"""
Redis å®¢æˆ·ç«¯æ¨¡å—
æä¾› Redis è¿æ¥å’Œæ•°æ®å­˜å‚¨åŠŸèƒ½ï¼Œæ”¯æŒï¼š
- ç²¾ç®€æ¨¡å¼ï¼ˆèŠ‚çœå†…å­˜ï¼‰
- é˜Ÿåˆ—é•¿åº¦é¢„è­¦
- æŒ‰æ•°æ®æ¥æºé…é¢ï¼ˆè½¯é™åˆ¶ï¼‰ä¸æ¥æºè®¡æ•°
"""
import json
import redis
from typing import Dict, Any, Optional, Tuple
from utils.logger import setup_logger

logger = setup_logger('redis_client')


class RedisClient:
    """Redis å®¢æˆ·ç«¯ç±»"""

    def __init__(
        self,
        host: str = 'localhost',
        port: int = 6379,
        db: int = 0,
        password: Optional[str] = None,
        queue_name: str = 'data_queue',
        storage_config: Optional[Dict[str, Any]] = None,
        source_quotas: Optional[Dict[str, float]] = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ– Redis å®¢æˆ·ç«¯

        Args:
            host: Redis ä¸»æœºåœ°å€
            port: Redis ç«¯å£
            db: Redis æ•°æ®åº“ç¼–å·
            password: Redis å¯†ç 
            queue_name: é˜Ÿåˆ—åç§°
            storage_config: å­˜å‚¨ä¼˜åŒ–é…ç½®å­—å…¸ï¼ˆæ¥è‡ª redis.storage_optimizationï¼‰
            source_quotas: æ¥æºé…é¢ï¼ˆæ¥è‡ª redis.source_quotasï¼‰ï¼Œ0-1 ä¹‹é—´
        """
        self.queue_name = queue_name

        # å­˜å‚¨ä¼˜åŒ–é…ç½®
        # å…¼å®¹ä¼ å…¥çš„å®Œæ•´ redis é…ç½®ï¼ˆstorage_optimization å¯èƒ½é€šè¿‡ **kwargs ä¼ å…¥ï¼‰
        storage_config = storage_config or kwargs.get('storage_optimization') or {}
        self.storage_config = storage_config
        self.slim_mode = self.storage_config.get('slim_mode', False)
        self.data_ttl = self.storage_config.get('data_ttl', None)
        self.max_keep = int(self.storage_config.get('max_keep', 10000))

        # æ¥æºé…é¢ï¼ˆè½¯é™åˆ¶ï¼‰
        self.source_quotas = source_quotas or kwargs.get('source_quotas') or {}
        # ä»¥ Redis Key è®°å½•æ¯ä¸ªæ¥æºçš„è®¡æ•°ï¼Œé¿å…å…¨é‡æ‰«æ
        self.source_count_prefix = f"{self.queue_name}:source_count:"

        try:
            self.client = redis.Redis(
                host=host,
                port=port,
                db=db,
                password=password,
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5,
            )
            # æµ‹è¯•è¿æ¥
            self.client.ping()
            logger.info(f"Redis è¿æ¥æˆåŠŸ: {host}:{port}/{db}")
            if self.slim_mode:
                logger.info("âœ“ ç²¾ç®€æ¨¡å¼å·²å¯ç”¨ (èŠ‚çœ60%ç©ºé—´)")
            if self.data_ttl:
                logger.info(f"âœ“ æ•°æ®TTL: {self.data_ttl}ç§’")
            logger.info(f"âœ“ æœ€å¤§ä¿ç•™: {self.max_keep}æ¡")
            if self.source_quotas:
                logger.info(f"âœ“ æ¥æºé…é¢å¯ç”¨: {self.source_quotas}")
        except redis.ConnectionError as e:
            logger.error(f"Redis è¿æ¥å¤±è´¥: {e}")
            raise
    
    def push_data(self, data: Dict[str, Any]) -> bool:
        """
        å°†æ•°æ®æ¨é€åˆ° Redis é˜Ÿåˆ—ï¼ˆæ”¯æŒç²¾ç®€æ¨¡å¼ï¼‰
        
        Args:
            data: è¦æ¨é€çš„æ•°æ®å­—å…¸
        
        Returns:
            bool: æ˜¯å¦æ¨é€æˆåŠŸ
        """
        try:
            # ğŸ”¥ ç²¾ç®€æ¨¡å¼ï¼šåªä¿ç•™æ ¸å¿ƒå­—æ®µ
            if self.slim_mode:
                data = self._slim_data(data)
            
            # åºåˆ—åŒ–ä¸º JSON
            json_data = json.dumps(data, ensure_ascii=False)
            
            # æ¨é€åˆ°åˆ—è¡¨
            # å…ˆæ£€æŸ¥æ¥æºé…é¢ï¼ˆè½¯é™åˆ¶ï¼šè¶…é¢åˆ™è·³è¿‡æœ¬æ¡ï¼‰
            source = data.get('source') or 'unknown'
            if self._exceeds_quota(source):
                logger.warning(f"âš ï¸  æ¥æº {source} å·²è¶…è¿‡é…é¢ï¼Œä¸¢å¼ƒæ–°æ•°æ®ä»¥ä¿æŠ¤æ€»é‡ï¼ˆsoft limitï¼‰")
                return False

            self.client.lpush(self.queue_name, json_data)
            # æ›´æ–°æ¥æºè®¡æ•°
            try:
                self.client.incr(self._source_count_key(source))
            except Exception:
                # è®¡æ•°å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                pass
            
            # ğŸ”¥ æ£€æŸ¥é˜Ÿåˆ—é•¿åº¦ï¼Œè¶…è¿‡é˜ˆå€¼è­¦å‘Š
            queue_length = self.client.llen(self.queue_name)
            if queue_length > self.max_keep:
                logger.warning(f"âš ï¸  é˜Ÿåˆ—é•¿åº¦ {queue_length} è¶…è¿‡é˜ˆå€¼ {self.max_keep}ï¼Œå»ºè®®å¯¼å‡º")
            
            logger.debug(f"æ•°æ®å·²æ¨é€åˆ° Redis: source={data.get('source')}")
            return True
        except Exception as e:
            logger.error(f"æ¨é€æ•°æ®åˆ° Redis å¤±è´¥: {e}")
            return False
    
    def _slim_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç²¾ç®€æ•°æ®å­—æ®µï¼ˆåªä¿ç•™æ ¸å¿ƒå­—æ®µï¼ŒèŠ‚çœ60%ç©ºé—´ï¼‰
        
        æ ¸å¿ƒå­—æ®µ:
        - title: æ ‡é¢˜
        - url: é“¾æ¥
        - published: å‘å¸ƒæ—¶é—´
        - source: æ•°æ®æº
        - feed_category: åˆ†ç±»ï¼ˆRSSä¸“ç”¨ï¼‰
        - language: è¯­è¨€
        - summary: æ‘˜è¦
        
        Args:
            data: åŸå§‹æ•°æ®
        
        Returns:
            ç²¾ç®€åçš„æ•°æ®
        """
        slim_fields = [
            'title',
            'url',
            'published',
            'source',
            'feed_category',
            'language',
            'summary',
            'timestamp'  # çˆ¬å–æ—¶é—´æˆ³
        ]
        
        slimmed = {k: v for k, v in data.items() if k in slim_fields}
        
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        if 'timestamp' not in slimmed and 'crawl_timestamp' in data:
            slimmed['timestamp'] = data['crawl_timestamp']
        
        if 'summary' not in slimmed and 'text' in data:
            slimmed['summary'] = data['text'][:500]  # åªä¿ç•™å‰500å­—ç¬¦
        
        return slimmed
    
    def push_batch(self, data_list: list) -> int:
        """
        æ‰¹é‡æ¨é€æ•°æ®åˆ° Redis
        
        Args:
            data_list: æ•°æ®å­—å…¸åˆ—è¡¨
        
        Returns:
            int: æˆåŠŸæ¨é€çš„æ•°æ®æ¡æ•°
        """
        success_count = 0
        try:
            # é€æ¡æ ¡éªŒæ¥æºé…é¢ï¼Œå¿…è¦æ—¶å¯ä¼˜åŒ–ä¸ºåˆ†ç»„æ‰¹å¤„ç†
            pipe = self.client.pipeline()
            to_incr = {}
            for data in data_list:
                if self.slim_mode:
                    data = self._slim_data(data)
                source = (data or {}).get('source') or 'unknown'
                if self._exceeds_quota(source):
                    continue
                json_data = json.dumps(data, ensure_ascii=False)
                pipe.lpush(self.queue_name, json_data)
                to_incr[source] = to_incr.get(source, 0) + 1
                success_count += 1
            if success_count:
                pipe.execute()
                # æ‰¹é‡å¢åŠ æ¥æºè®¡æ•°
                for s, c in to_incr.items():
                    try:
                        self.client.incrby(self._source_count_key(s), c)
                    except Exception:
                        pass
                logger.info(f"æ‰¹é‡æ¨é€ {success_count} æ¡æ•°æ®åˆ° Redis")
        except Exception as e:
            logger.error(f"æ‰¹é‡æ¨é€æ•°æ®å¤±è´¥: {e}")

        return success_count
    
    def get_queue_length(self) -> int:
        """
        è·å–é˜Ÿåˆ—é•¿åº¦
        
        Returns:
            int: é˜Ÿåˆ—ä¸­çš„æ•°æ®æ¡æ•°
        """
        try:
            length = self.client.llen(self.queue_name)
            return length
        except Exception as e:
            logger.error(f"è·å–é˜Ÿåˆ—é•¿åº¦å¤±è´¥: {e}")
            return -1
    
    def peek_data(self, count=10) -> list:
        """
        æŸ¥çœ‹é˜Ÿåˆ—ä¸­çš„æ•°æ®ï¼ˆä¸ç§»é™¤ï¼‰
        
        Args:
            count: æŸ¥çœ‹çš„æ•°æ®æ¡æ•°
        
        Returns:
            list: æ•°æ®åˆ—è¡¨
        """
        try:
            data_list = self.client.lrange(self.queue_name, 0, count - 1)
            return [json.loads(item) for item in data_list]
        except Exception as e:
            logger.error(f"æŸ¥çœ‹é˜Ÿåˆ—æ•°æ®å¤±è´¥: {e}")
            return []

    # ============== é…é¢ä¸è®¡æ•° ==============
    def _source_count_key(self, source: str) -> str:
        return f"{self.source_count_prefix}{source}"

    def _quota_limit(self, source: str) -> Optional[int]:
        """è¿”å›æŸæ¥æºçš„é…é¢ä¸Šé™æ¡æ•°ï¼ˆåŸºäº max_keep ä¸ç™¾åˆ†æ¯”ï¼‰ï¼Œæ— åˆ™è¿”å› Noneã€‚"""
        if not self.source_quotas:
            return None
        q = self.source_quotas.get(source)
        if q is None:
            return None
        try:
            return int(self.max_keep * float(q))
        except Exception:
            return None

    def _exceeds_quota(self, source: str) -> bool:
        limit = self._quota_limit(source)
        if not limit:
            return False
        try:
            # è¯»å–å½“å‰æ¥æºè®¡æ•°
            cnt = int(self.client.get(self._source_count_key(source)) or 0)
            return cnt >= limit
        except Exception:
            return False

    def rebuild_source_counts(self, max_scan: Optional[int] = None) -> Tuple[int, Dict[str, int]]:
        """
        å…¨é‡ï¼ˆæˆ–éƒ¨åˆ†ï¼‰æ‰«æé˜Ÿåˆ—ï¼Œé‡å»ºæ¥æºè®¡æ•°é”®ã€‚
        æ³¨æ„ï¼šO(n) æ“ä½œï¼Œè¯·åœ¨å¯¼å‡ºä¿®å‰ªåè°ƒç”¨ã€‚

        Args:
            max_scan: æœ€å¤šæ‰«æçš„æ¡æ•°ï¼ˆä»é˜Ÿåˆ—å¤´éƒ¨å¼€å§‹ï¼‰ï¼Œé»˜è®¤å…¨é‡

        Returns:
            (scanned, counts) å…ƒç»„
        """
        try:
            # æ¸…ç†ç°æœ‰è®¡æ•°
            # ç®€åŒ–å¤„ç†ï¼šä¸åˆ é™¤æ—§ keyï¼Œç›´æ¥è¦†ç›– set å€¼
            length = self.client.llen(self.queue_name)
            scan_n = length if max_scan is None else min(length, max_scan)
            if scan_n <= 0:
                return 0, {}
            # ä»å¤´éƒ¨è¯»å–æœ€æ–°çš„ scan_n æ¡
            data_list = self.client.lrange(self.queue_name, 0, scan_n - 1)
            counts: Dict[str, int] = {}
            for item in data_list:
                try:
                    d = json.loads(item)
                    s = (d or {}).get('source') or 'unknown'
                    counts[s] = counts.get(s, 0) + 1
                except Exception:
                    continue
            # å›å†™è®¡æ•°
            pipe = self.client.pipeline()
            for s, c in counts.items():
                pipe.set(self._source_count_key(s), c)
            pipe.execute()
            logger.info(f"æ¥æºè®¡æ•°é‡å»ºå®Œæˆï¼šæ‰«æ {scan_n} æ¡ï¼Œæ¥æºæ•° {len(counts)}")
            return scan_n, counts
        except Exception as e:
            logger.error(f"é‡å»ºæ¥æºè®¡æ•°å¤±è´¥: {e}")
            return 0, {}
    
    def close(self):
        """å…³é—­ Redis è¿æ¥"""
        try:
            self.client.close()
            logger.info("Redis è¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­ Redis è¿æ¥å¤±è´¥: {e}")
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """
        è·å– Redis å†…å­˜ä½¿ç”¨æƒ…å†µ
        
        Returns:
            dict: å†…å­˜ä½¿ç”¨ä¿¡æ¯
            {
                'used_memory_mb': 123.45,        # å·²ä½¿ç”¨å†…å­˜(MB)
                'used_memory_human': '123.45M',  # äººç±»å¯è¯»æ ¼å¼
                'used_memory_peak_mb': 200.00,   # å³°å€¼å†…å­˜(MB)
                'used_memory_peak_human': '200M' # å³°å€¼äººç±»å¯è¯»æ ¼å¼
            }
        """
        try:
            info = self.client.info('memory')
            return {
                'used_memory_mb': info['used_memory'] / 1024 / 1024,
                'used_memory_human': info['used_memory_human'],
                'used_memory_peak_mb': info['used_memory_peak'] / 1024 / 1024,
                'used_memory_peak_human': info['used_memory_peak_human']
            }
        except Exception as e:
            logger.error(f"è·å– Redis å†…å­˜ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'used_memory_mb': 0,
                'used_memory_human': 'N/A',
                'used_memory_peak_mb': 0,
                'used_memory_peak_human': 'N/A'
            }

