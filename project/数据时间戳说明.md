# â° æ•°æ®æ—¶é—´æˆ³è¯´æ˜

**é‡è¦**: æ‰€æœ‰æŠ“å–çš„æ•°æ®éƒ½ä¿å­˜äº†åŸå§‹å‘å¸ƒæ—¶é—´!

---

## âœ… æ—¶é—´æˆ³å­—æ®µæ±‡æ€»

| æ•°æ®æº | æ—¶é—´å­—æ®µ | æ ¼å¼ | è¯´æ˜ |
|--------|---------|------|------|
| **Reddit** | `timestamp` | Unixæ—¶é—´æˆ³ | å¸–å­/è¯„è®ºçš„å‘å¸ƒæ—¶é—´ (`created_utc`) |
| **RSS** | `timestamp`<br>`published`<br>`crawl_timestamp` | Unixæ—¶é—´æˆ³ | æ–‡ç« å‘å¸ƒæ—¶é—´<br>åŸå§‹å‘å¸ƒæ—¶é—´<br>æŠ“å–æ—¶é—´ |
| **NewsAPI** | `timestamp`<br>`published_at` | Unixæ—¶é—´æˆ³<br>ISO 8601 | æ–‡ç« å‘å¸ƒæ—¶é—´<br>åŸå§‹æ—¶é—´å­—ç¬¦ä¸² |
| **Twitter** | `timestamp` | Unixæ—¶é—´æˆ³ | æ¨æ–‡å‘å¸ƒæ—¶é—´ (`created_at`) |
| **StockTwits** | `timestamp` | Unixæ—¶é—´æˆ³ | æ¶ˆæ¯å‘å¸ƒæ—¶é—´ (`created_at`) |

---

## ğŸ“Š å®é™…ç¤ºä¾‹

### Reddit æ•°æ®
```json
{
  "text": "Tesla stock analysis...",
  "source": "reddit_post",
  "timestamp": 1729411200,  // â† å‘å¸ƒæ—¶é—´ (2024-10-20 08:00:00)
  "post_id": "xyz123",
  "subreddit": "investing"
}
```

**è½¬æ¢ä¸ºäººç±»å¯è¯»æ—¶é—´**:
```python
from datetime import datetime
dt = datetime.fromtimestamp(1729411200)
print(dt)  # 2024-10-20 08:00:00
```

### RSS æ•°æ®
```json
{
  "text": "Federal Reserve announces...",
  "source": "rss",
  "timestamp": 1729411200,      // â† å‘å¸ƒæ—¶é—´
  "published": 1729411200,      // â† åŸå§‹å‘å¸ƒæ—¶é—´
  "crawl_timestamp": 1729414800, // â† æŠ“å–æ—¶é—´ (1å°æ—¶å)
  "url": "https://..."
}
```

**æ—¶é—´å·®åˆ†æ**:
```python
publish_time = datetime.fromtimestamp(1729411200)  # 8:00
crawl_time = datetime.fromtimestamp(1729414800)    # 9:00
delay = crawl_time - publish_time  # 1å°æ—¶å»¶è¿Ÿ
```

### NewsAPI æ•°æ®
```json
{
  "text": "Stock market today...",
  "source": "newsapi",
  "timestamp": 1729411200,              // â† Unixæ—¶é—´æˆ³
  "published_at": "2024-10-20T08:00:00Z", // â† ISOæ ¼å¼
  "title": "Market Update"
}
```

### Twitter æ•°æ®
```json
{
  "text": "$SPY breaking out!",
  "source": "twitter",
  "timestamp": 1729411200,  // â† æ¨æ–‡å‘å¸ƒæ—¶é—´
  "tweet_id": "1234567890",
  "author": "trader_joe"
}
```

---

## ğŸ” æ—¶é—´èŒƒå›´éªŒè¯

### æ£€æŸ¥æ•°æ®æ–°é²œåº¦

**æ–¹æ³• 1: å¯¼å‡ºåæ£€æŸ¥**
```python
import json
from datetime import datetime

# è¯»å–å¯¼å‡ºçš„æ•°æ®
with open('data_exports/data_export_xxx.json') as f:
    data = json.load(f)

# æ£€æŸ¥æœ€æ–°å’Œæœ€æ—§çš„æ•°æ®
timestamps = [item['timestamp'] for item in data]
newest = datetime.fromtimestamp(max(timestamps))
oldest = datetime.fromtimestamp(min(timestamps))

print(f"æœ€æ–°æ•°æ®: {newest}")
print(f"æœ€æ—§æ•°æ®: {oldest}")
print(f"æ—¶é—´è·¨åº¦: {newest - oldest}")
```

**æ–¹æ³• 2: Redis å®æ—¶æ£€æŸ¥**
```python
import redis
import json
from datetime import datetime

r = redis.Redis(host='localhost', port=6379, decode_responses=True)
items = r.lrange('data_queue', 0, 100)  # å–æœ€æ–°100æ¡

timestamps = []
for item in items:
    data = json.loads(item)
    timestamps.append(data.get('timestamp', 0))

if timestamps:
    newest = datetime.fromtimestamp(max(timestamps))
    print(f"æœ€æ–°æ•°æ®æ—¶é—´: {newest}")
```

---

## â±ï¸ å½“å‰æŠ“å–ç­–ç•¥

### Reddit
- **API**: `subreddit.new(limit=50)`
- **æ—¶é—´èŒƒå›´**: æœ€æ–° 50 æ¡å¸–å­
- **å‘å¸ƒæ—¶é—´**: é€šå¸¸åœ¨ **å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶** å†…
- âœ… **å®æ—¶æ€§**: ä¼˜ç§€

### RSS
- **æŠ“å–**: æ‰€æœ‰ Feed ä¸­çš„æ–‡ç« 
- **å‘å¸ƒæ—¶é—´**: Feed ä¸­é€šå¸¸åŒ…å« **æœ€è¿‘ 24-48 å°æ—¶** çš„æ–‡ç« 
- âœ… **å®æ—¶æ€§**: è‰¯å¥½

### NewsAPI
- **å‚æ•°**: `from_param=ä»Šå¤©` (å·²ä¼˜åŒ–)
- **å‘å¸ƒæ—¶é—´**: **ä»Šå¤© 0 ç‚¹å** çš„æ–‡ç« 
- âš ï¸ **é—®é¢˜**: é»˜è®¤æŠ“å– 1 å¤©å‰,éœ€è¦ä¼˜åŒ–

### Twitter X API
- **ç«¯ç‚¹**: `search/recent`
- **æ—¶é—´èŒƒå›´**: æœ€è¿‘ **7 å¤©**
- **æ’åº**: æŒ‰ç›¸å…³æ€§æˆ–æ—¶é—´
- âš ï¸ **é—®é¢˜**: å¯èƒ½åŒ…å«å‡ å¤©å‰çš„æ¨æ–‡

### StockTwits
- **API**: `streams/symbol/{symbol}`
- **æ—¶é—´èŒƒå›´**: æœ€æ–° 30 æ¡æ¶ˆæ¯
- **å‘å¸ƒæ—¶é—´**: é€šå¸¸åœ¨ **å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶** å†…
- âœ… **å®æ—¶æ€§**: ä¼˜ç§€

---

## ğŸš¨ éœ€è¦ä¼˜åŒ–çš„åœ°æ–¹

### 1. NewsAPI ä¼˜åŒ– âš ï¸ é‡è¦

**å½“å‰é—®é¢˜**: 
```python
days_back = self.config.get('days_back', 1)  # é»˜è®¤ 1 å¤©å‰
from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
```

**å»ºè®®ä¿®æ”¹**:
```python
days_back = 0  # æ”¹ä¸ºä»Šå¤©
# æˆ–è€…ä½¿ç”¨å°æ—¶çº§ç²¾åº¦
from_date = (datetime.now() - timedelta(hours=2)).isoformat()
```

**å½±å“**: 
- âŒ å½“å‰å¯èƒ½æŠ“åˆ°æ˜¨å¤©çš„æ–°é—»
- âœ… åº”è¯¥æŠ“å–æœ€è¿‘ 1-2 å°æ—¶çš„æ–°é—»

### 2. Twitter æ’åºä¼˜åŒ– âš ï¸ ä¸­ç­‰

**å½“å‰é—®é¢˜**: 
Twitter API é»˜è®¤æŒ‰ç›¸å…³æ€§æ’åº,ä¸ä¸€å®šæ˜¯æœ€æ–°

**å»ºè®®ä¼˜åŒ–**:
```python
# æ·»åŠ æ—¶é—´è¿‡æ»¤
params = {
    "query": f"{query} -is:retweet",  # æ’é™¤è½¬æ¨
    "max_results": 10,
    "start_time": (datetime.now() - timedelta(hours=6)).isoformat() + "Z"  # æœ€è¿‘6å°æ—¶
}
```

---

## ğŸ“ˆ æ•°æ®æ–°é²œåº¦åˆ†æ

### é¢„æœŸæ—¶é—´åˆ†å¸ƒ

**æ­£å¸¸æƒ…å†µ** (æ¯å°æ—¶è¿è¡Œä¸€æ¬¡):

| æ•°æ®æº | æ•°æ®å¹´é¾„ | è¯´æ˜ |
|--------|---------|------|
| Reddit | 0-60åˆ†é’Ÿ | æ¯å°æ—¶æŠ“æœ€æ–°50æ¡ |
| RSS | 0-2å°æ—¶ | Feedæ›´æ–°é¢‘ç‡ |
| NewsAPI | **0-24å°æ—¶** | âš ï¸ éœ€ä¼˜åŒ–ä¸º 0-2å°æ—¶ |
| Twitter | 0-7å¤© | âš ï¸ éœ€ä¼˜åŒ–ä¸º 0-6å°æ—¶ |
| StockTwits | 0-60åˆ†é’Ÿ | æœ€æ–°30æ¡æ¶ˆæ¯ |

**ä¼˜åŒ–å**:

| æ•°æ®æº | æ•°æ®å¹´é¾„ | æ”¹è¿› |
|--------|---------|------|
| Reddit | 0-60åˆ†é’Ÿ | ä¸å˜ |
| RSS | 0-2å°æ—¶ | ä¸å˜ |
| NewsAPI | **0-2å°æ—¶** | âœ… ä¼˜åŒ– |
| Twitter | **0-6å°æ—¶** | âœ… ä¼˜åŒ– |
| StockTwits | 0-60åˆ†é’Ÿ | ä¸å˜ |

---

## ğŸ¯ ä¼˜åŒ–å»ºè®®

### ç«‹å³ä¼˜åŒ–

**1. NewsAPI æ”¹ä¸ºä»Šå¤©**
```yaml
# config.yaml æ·»åŠ 
newsapi:
  days_back: 0  # ä»Šå¤©,ä¸æ˜¯æ˜¨å¤©
```

**2. Twitter æ·»åŠ æ—¶é—´è¿‡æ»¤**
```python
# twitter_v2_crawler.py
# æ·»åŠ  start_time å‚æ•°
```

### ç›‘æ§è„šæœ¬

åˆ›å»º `check_data_freshness.py`:
```python
import redis
import json
from datetime import datetime, timedelta

r = redis.Redis(host='localhost', port=6379, decode_responses=True)
items = r.lrange('data_queue', 0, 1000)

# æŒ‰æ•°æ®æºåˆ†ç»„
sources = {}
for item in items:
    data = json.loads(item)
    source = data.get('source', 'unknown')
    timestamp = data.get('timestamp', 0)
    
    if source not in sources:
        sources[source] = []
    sources[source].append(timestamp)

# åˆ†ææ¯ä¸ªæ•°æ®æº
now = datetime.now()
for source, timestamps in sources.items():
    if not timestamps:
        continue
    
    newest = datetime.fromtimestamp(max(timestamps))
    oldest = datetime.fromtimestamp(min(timestamps))
    avg_age = (now - newest).total_seconds() / 3600
    
    print(f"\n{source}:")
    print(f"  æ•°æ®é‡: {len(timestamps)}")
    print(f"  æœ€æ–°: {newest} (è·ä»Š {avg_age:.1f} å°æ—¶)")
    print(f"  æœ€æ—§: {oldest}")
    print(f"  è·¨åº¦: {newest - oldest}")
```

---

## âœ… æ€»ç»“

**å¥½æ¶ˆæ¯**:
- âœ… æ‰€æœ‰æ•°æ®éƒ½ä¿å­˜äº†å‘å¸ƒæ—¶é—´
- âœ… ä½¿ç”¨æ ‡å‡† Unix æ—¶é—´æˆ³ (æ˜“äºåˆ†æ)
- âœ… å¤§éƒ¨åˆ†æ•°æ®æºå®æ—¶æ€§è‰¯å¥½

**éœ€è¦ä¼˜åŒ–**:
- âš ï¸ NewsAPI: æ”¹ä¸ºæŠ“å–ä»Šå¤©çš„æ•°æ®
- âš ï¸ Twitter: æ·»åŠ æ—¶é—´è¿‡æ»¤ (æœ€è¿‘6å°æ—¶)

**æ•°æ®å¯ç”¨æ€§**:
- âœ… å¯ä»¥æŒ‰æ—¶é—´æ’åº
- âœ… å¯ä»¥è¿‡æ»¤ç‰¹å®šæ—¶é—´æ®µ
- âœ… å¯ä»¥åˆ†æå‘å¸ƒå»¶è¿Ÿ
- âœ… æ”¯æŒæ—¶é—´åºåˆ—åˆ†æ

---

**ä¸‹ä¸€æ­¥**: ç«‹å³ä¼˜åŒ– NewsAPI å’Œ Twitter çš„æ—¶é—´å‚æ•°!
